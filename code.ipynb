{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MedSRGAN 구현 \n",
    "\n",
    "참고: https://github.com/04RR/MedSRGAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as ttf\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "\n",
    "\n",
    "# 난수 고정 함수\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 난수 고정\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/ykjeong/MedSRGAN/dataset'\n",
    "path_list = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
    "\n",
    "class GAN_Data(Dataset):\n",
    "    def __init__(self, path_list, transform_lr=None, transform_hr=None):\n",
    "        self.path_list = path_list\n",
    "        self.transform_lr = transform_lr\n",
    "        self.transform_hr = transform_hr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.path_list[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        \n",
    "        if self.transform_lr:\n",
    "            lr_image = self.transform_lr(image)\n",
    "        if self.transform_hr:\n",
    "            hr_image = self.transform_hr(image)\n",
    "        \n",
    "        return lr_image, hr_image\n",
    "\n",
    "\n",
    "transform_lr = ttf.Compose([\n",
    "    ttf.Resize((128, 128)),  # LR 이미지 크기\n",
    "    ttf.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_hr = ttf.Compose([\n",
    "    ttf.Resize((128, 128)),  # HR 이미지 크기\n",
    "    ttf.GaussianBlur(3, sigma=(0.1, 2.0)),  # Gaussian Blur 추가\n",
    "    ttf.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "dataset = GAN_Data(path_list, transform_lr=transform_lr, transform_hr=transform_hr)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWMAB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, (1, 1), stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_ = self.layer1(x)\n",
    "        x__ = self.layer2(x_)\n",
    "        x = x__ * x_ + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class ShortResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([RWMAB(in_channels) for _ in range(16)])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_ = x.clone()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_ = layer(x_)\n",
    "\n",
    "        return x_ + x\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=1, blocks=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1)\n",
    "\n",
    "        self.short_blocks = nn.ModuleList(\n",
    "            [ShortResidualBlock(64) for _ in range(blocks)]\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, (1, 1), stride=1, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 최종 출력 채널 수를 1로 줄이기 위한 Conv2d 레이어\n",
    "        self.final_conv = nn.Conv2d(64, 1, (3, 3), stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x_ = x.clone()\n",
    "\n",
    "        for layer in self.short_blocks:\n",
    "            x_ = layer(x_)\n",
    "\n",
    "        x = torch.cat([self.conv2(x_), x], dim=1)\n",
    "        x = self.conv3(x)\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.layer(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, in_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        # 특징 추출\n",
    "        x_1 = self.feature_extractor(x1)\n",
    "        x_2 = self.feature_extractor(x2)\n",
    "        \n",
    "        # 특징 결합\n",
    "        x = torch.cat([x_1, x_2], dim=1)\n",
    "\n",
    "        # 분류\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator().to(device)\n",
    "disc = Discriminator(img_size=(128, 128), in_channels=1).to(device)\n",
    "\n",
    "# 학습률 이 이상으로 올릴 경우 학습되지 않는 현상 발생 \n",
    "optimizer_G = optim.Adam(gen.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(disc.parameters(), lr=1e-4, betas=(0.5, 0.999)) \n",
    "\n",
    "loss_function = torch.nn.L1Loss().to(device)\n",
    "gan_loss = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    gen,\n",
    "    disc,\n",
    "    dataloader,\n",
    "    epochs,\n",
    "    optimizer_G,\n",
    "    optimizer_D,\n",
    "    scaler,\n",
    "    loss_function,\n",
    "    gan_loss,\n",
    "):\n",
    "\n",
    "    t_loss_G, t_loss_D = [], []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        e_loss_G, e_loss_D = [], []\n",
    "\n",
    "        for data in dataloader:\n",
    "            hr_img, lr_img = data\n",
    "            hr_img = hr_img.float().to(device)\n",
    "            lr_img = lr_img.float().to(device)\n",
    "\n",
    "            valid = torch.tensor(np.ones((1, 1)), dtype=torch.float32, device=device).detach()\n",
    "            fake = torch.tensor(np.zeros((1, 1)), dtype=torch.float32, device=device).detach()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "\n",
    "                # Train Generator\n",
    "\n",
    "                pred_hr = gen(lr_img)\n",
    "\n",
    "                content_loss = loss_function(pred_hr, hr_img)\n",
    "                feature_loss = 0.0\n",
    "\n",
    "                pred_real = disc(hr_img.detach(), lr_img)\n",
    "                pred_fake = disc(pred_hr, lr_img)\n",
    "\n",
    "                gan_loss_num = gan_loss(\n",
    "                    pred_fake - pred_real.mean(0, keepdim=True), valid\n",
    "                )\n",
    "\n",
    "                loss_G = content_loss * 0.1 + feature_loss * 0.1 + gan_loss_num\n",
    "\n",
    "                optimizer_G.zero_grad()\n",
    "                scaler.scale(loss_G).backward()\n",
    "                scaler.step(optimizer_G)\n",
    "                scaler.update()\n",
    "                e_loss_G.append(loss_G)\n",
    "\n",
    "                # Train Discriminator\n",
    "\n",
    "                pred_real = disc(hr_img, lr_img)\n",
    "                pred_fake = disc(pred_hr.detach(), lr_img)\n",
    "\n",
    "                loss_real = gan_loss(pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "                loss_fake = gan_loss(pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "\n",
    "                loss_real_num = gan_loss(pred_real, valid)\n",
    "                loss_fake_num = gan_loss(pred_fake, fake)\n",
    "\n",
    "                loss_D = ((loss_real + loss_fake) / 2) + (\n",
    "                    (loss_real_num + loss_fake_num) / 2\n",
    "                )\n",
    "\n",
    "                optimizer_D.zero_grad()\n",
    "                scaler.scale(loss_D).backward()\n",
    "                scaler.step(optimizer_D)\n",
    "                scaler.update()\n",
    "                e_loss_D.append(loss_D)\n",
    "\n",
    "        t_loss_D.append(sum(e_loss_D) / len(e_loss_D))\n",
    "        t_loss_G.append(sum(e_loss_G) / len(e_loss_G))\n",
    "\n",
    "        print(\n",
    "            f\"{epoch+1}/{epochs} -- Gen Loss: {sum(t_loss_G) / len(t_loss_G)} -- Disc Loss: {sum(t_loss_D) / len(t_loss_D)}\"\n",
    "        )\n",
    "\n",
    "        torch.save(gen, \"./gen_{epoch}\")\n",
    "        torch.save(disc, \"./disc_{epoch}\")\n",
    "\n",
    "    return t_loss_G, t_loss_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 -- Gen Loss: 0.7146836519241333 -- Disc Loss: 1.3877990245819092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:22<21:23, 142.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 -- Gen Loss: 0.704403281211853 -- Disc Loss: 1.387054443359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:30<17:50, 133.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 -- Gen Loss: 0.7009477615356445 -- Disc Loss: 1.386803150177002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [06:38<15:18, 131.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 -- Gen Loss: 0.6992075443267822 -- Disc Loss: 1.3866766691207886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [08:43<12:52, 128.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 -- Gen Loss: 0.6981515884399414 -- Disc Loss: 1.3866006135940552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [10:47<10:35, 127.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 -- Gen Loss: 0.6974424719810486 -- Disc Loss: 1.3865498304367065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [12:51<08:24, 126.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 -- Gen Loss: 0.6996310353279114 -- Disc Loss: 1.3862272500991821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [14:57<06:18, 126.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/10 -- Gen Loss: 0.698916494846344 -- Disc Loss: 1.3862359523773193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [17:02<04:11, 125.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/10 -- Gen Loss: 0.6983544826507568 -- Disc Loss: 1.3862427473068237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [19:04<02:04, 124.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 -- Gen Loss: 0.6979025602340698 -- Disc Loss: 1.3862481117248535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:09<00:00, 126.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6941, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6940, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6940, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6939, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.6938, device='cuda:0', grad_fn=<DivBackward0>)],\n",
       " [tensor(1.3878, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3843, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(1.3863, device='cuda:0', grad_fn=<DivBackward0>)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=10\n",
    "fit(gen, disc, dataloader, epochs, optimizer_G, optimizer_D, scaler, loss_function, gan_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.67166461356242, 37.865413160832574)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def visualize_results(generator, index, device, dataset):\n",
    "    set_seed(42)\n",
    "    generator.eval()\n",
    "    \n",
    "    # Load specific samples from the dataset\n",
    "    hr_img, lr_img = dataset[index]\n",
    "    hr_img = hr_img.unsqueeze(0).to(device)\n",
    "    lr_img = lr_img.unsqueeze(0).to(device) \n",
    "    \n",
    "    # 입력 이미지(lr_img)를 생성자(generator) 모델을 통해 변환\n",
    "    with torch.no_grad():\n",
    "        generated_img = generator(lr_img).detach().cpu()\n",
    "    \n",
    "    # 첫 번째 이미지만 시각적으로 비교\n",
    "    hr_example = hr_img[0].permute(1, 2, 0).cpu().numpy()\n",
    "    lr_example = lr_img[0].permute(1, 2, 0).cpu().numpy()\n",
    "    generated_example = generated_img[0].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # PSNR 계산\n",
    "    psnr_value_1 = peak_signal_noise_ratio(hr_example, generated_example)\n",
    "    psnr_value_2 = peak_signal_noise_ratio(lr_example, generated_example)\n",
    "        \n",
    "    # PSNR 값 반환\n",
    "    return psnr_value_1, psnr_value_2\n",
    "\n",
    "index = 2\n",
    "visualize_results(gen, index, 'cuda', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR ground truth - output: 38.4463 dB\n",
      "Average PSNR ground truth - input : 36.8205 dB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모든 데이터에 대해 PSNR 평균 계산 예시\n",
    "def calculate_average_psnr(generator, device, dataset):\n",
    "    psnr_1_list = []\n",
    "    psnr_2_list = []\n",
    "    num_samples = len(dataset)  # 데이터셋의 샘플 수\n",
    "    \n",
    "    for index in range(num_samples):\n",
    "        psnr_1, psnr_2 = visualize_results(generator, index, device, dataset)\n",
    "        psnr_1_list.append(psnr_1)\n",
    "        psnr_2_list.append(psnr_2)\n",
    "    \n",
    "    average_psnr_1 = np.mean(psnr_1_list)\n",
    "    average_psnr_2 = np.mean(psnr_2_list)\n",
    "    \n",
    "    return average_psnr_1, average_psnr_2\n",
    "\n",
    "# 예시 실행\n",
    "avg_psnr_1, avg_psnr_2 = calculate_average_psnr(gen, device, dataset)\n",
    "\n",
    "print(f'Average PSNR ground truth - output: {avg_psnr_1:.4f} dB')\n",
    "print(f'Average PSNR ground truth - input : {avg_psnr_2:.4f} dB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
